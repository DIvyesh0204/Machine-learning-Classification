   
 
 Beginner’s Hypothesis 2021 Submission                                                                                                 

Team name: Procrastinator
Participant: DIVYESH 

Songs classification on the basis of genre using existing   dataset

                       Project Overview
The given ML project is a multiclass classification project based on supervised learning. On the basis of the given training data set, music genre was predicted of the test data set. Different ML models were tried and tested, but catboost classifier model gave the best results.

                                Libraries used               
•	Matplotlib
•	Catboost
•	Scikit learn
•	Pandas
•	Seaborn
Coding implementation for the project was done in Jupyter Notebook. 

                              Sections
1)	Hypothesis
2)	Data analysis
3)	Dataset preparation
4)	Model selection
5)	Model evaluation
6)	Conclusion












                                 
Hypothesis

In this project, our objective is to predict the music genre by the features of the given song. Various criteria play an impeccable role in identifying the music genre, this includes “feelings”, “loudness”, “danceability”,” energy” etc. Genre of a song are classified into 7 different categories on the basis of the above-mentioned criteria. Hence, this is a multi-class classification situation. So, a classification ML model will be required to predict the genre of the song by the measurements of the above-mentioned features.

                      Data Analysis 
The dataset for the given project consists of training and   testing data. Training dataset consists of 27 fields and 17743 records and test dataset contains 26 fields and 5914 records.
Value distribution of genre in the training data set is as follows: -
   Genre       Counts  
       4	      4293
       1        411 
       0    		2865
       6    		2544
       3    		2396
       5    		1595
       2     		639

From the table given below, it can be seen that the given training data as well as the test data contain a large number of nan values. The given dataset contains plenty of nan values and suitable techniques have to be used which will be discussed further in the documentation.

 

            fields                    count       

		Id			    0	
            release_date                876
            dating                      863
            violence                    878
            world/life                  928
            night/time                  908
            shake the audience          915
            family/gospel               939
            romantic                    902
            communication               907
            obscene                     876 
            music                       836
            movement/places             885
            light/visual perceptions    872  
            family/spiritual            894
            like/girls                  891
            sadness                     910
            feelings                    929
            danceability                865
            loudness                    842
            acousticness                900
            instrumentalness            912
            valence                     858
            energy                      849
            age                         869
            topic                       874







Analysis of data also includes data visualization. 
Data visualization provides a visual summary and makes it easier to identify patterns and trends than looking through thousands of rows in a spreadsheet. We can visualize the correlation matrix which correlates the different features with the help of a heatmap. The heatmap is generated by importing the seaborn library and matplotlib also has been used for data plotting. 
  Heatmap relating all the different features of the correlation matrix

                       



 
                        Dataset preparation

1)Feature selection and engineering
Testing and training data set were given separately in the problem statement. Most of the listed features were having quite similar values, and all the features were used in the training model.
A correlation matrix was also created around the “music” feature.


music                       1.000000
family/spiritual            0.662411
shake the audience          0.656263
family/gospel               0.653973
dating                      0.646221
like/girls                  0.629618
feelings                    0.613722
light/visual perceptions    0.609939
movement/places             0.566385
romantic                    0.563775
night/time                  0.523033
communication               0.494632
instrumentalness            0.398573
sadness                     0.361822
obscene                     0.358091
world/life                  0.350848
violence                    0.328229
acousticness                0.302793
danceability                0.210801
age                         0.203546
valence                     0.171578
loudness                    0.148415
energy                      0.074347
release_date               -0.117173
topic                      -0.348114


Since any concrete conclusion didn’t arrive regarding the preferential selection of features, hence all the features were included in the final training data set.

2)Dealing with nan values
The given data set had plenty of cells with empty values. This has been evaluated above. This issue can be dealt with by adding some specific value such as the median, mode or mean. Though this works well, we can also do some other methods to fill null value in the training data set, we can also fill null values using special functions from the Sci-kit learn library. From Sci-kit learn library KNN imputer can be implemented for filling the nan values in the dataset, as here the values are decided based on the values of the k-nearest neighbours.

3)Feature Scaling 
Feature scaling is a crucial part of data processing which shouldn’t be overlooked. Two of the popular feature scaling techniques include normalization and standardization. In the given data set, the features “release¬_date”, “topic” and “music” have different range of values. When we apply machine learning algorithms on the values of features, the performance of the algorithm will be impacted by different range of values of features and we do not want our algorithm to be biased towards one feature. 
Hence, for assigning similar range of values to all the features, I have used the Standardization approach on the data set. This can be done by importing “StandardScaler” function from the Sci-kit learn library.

4) Splitting the training data set
The given training data set is later split into 2 for deducing the performance of various algorithms on the dataset. 
                                 Model Selection
After repeated trials and evaluation with Logistic regression and Random Forest Classifier models, finally Catboostclassifier showed better results due to multiclass classification scenario. 
CatboostClassifier provides compatibility with the scikit learn tools. If overfitting occurs, CatBoost can stop the training earlier than the training parameters dictate. This option is set in the starting parameters. It also allows to perform cross validation on the given training data set.

               
                     Model Evaluation
Model is evaluated based on its F1 score. The F1-score is a measure of model’s accuracy on a dataset. The F1- score for the catboost classifier is evaluated using the “score” method in it.  The training data was split further into another training and testing data as we had to check the accuracy of different classification models on the training data set. 
Logistic Regression was also implemented but its accuracy was close to 0.28, Random Classifier too had an accuracy of 0.41 approximately. 
Catboost model gave the highest accuracy among others hence it was implemented.
The score evaluated for the data set was approximately 0.43 using Catboost classifier. 
Classification report for the model is given in the table below.

   		 precision    recall    f1-score           

           0       0.39      0.28      0.33      
           1       0.43      0.54      0.48       
           2       0.51      0.50      0.51       
           3       0.49      0.40      0.44       
           4       0.39      0.48      0.43       
           5       0.47      0.47      0.47       
           6       0.48      0.36      0.41       

    accuracy                           0.43      
   macro avg       0.45      0.43      0.44      
weighted avg       0.44      0.43      0.43     
 


From the above table, it can be deduced that predictions made by the classification model for genre ‘2’ were the most accurate and predictions for genre ‘0’ were the least.

                                      
                                       Conclusion 

It was observed that by applying the suitable machine learning model, still the accuracy of prediction of ‘genre’ was merely 0.43 which is a pretty low value. The accuracy of the prediction can improve if we do further investigation over important features. Also, there would be better machine learning models which might give better accuracy compared to the current       
value.




